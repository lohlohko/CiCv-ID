{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18bce1d9-bb6d-41bb-993b-7fca2865c6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import language_tool_python\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0efb70f-e4e9-4f27-9821-1f0023970fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['validation.csv', 'test.csv']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list all csv files only\n",
    "csv_files = glob.glob('*.{}'.format('csv'))\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d51ada09-a775-4b19-bbf5-1ce5f1bafbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>corrections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So I think we can not live if old people could...</td>\n",
       "      <td>['So I think we would not be alive if our ance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For not use car .</td>\n",
       "      <td>['Not for use with a car . ' 'Do not use in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Here was no promise of morning except that we ...</td>\n",
       "      <td>['Here was no promise of morning , except that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thus even today sex is considered as the least...</td>\n",
       "      <td>['Thus , even today , sex is considered as the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image you salf you are wark in factory just to...</td>\n",
       "      <td>[\"Imagine yourself you are working in factory ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>But I disegree this opinion because often the ...</td>\n",
       "      <td>[\"But I disagree with this opinion because oft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>it gives him many apprtunites in the life , an...</td>\n",
       "      <td>['It gives him many opportunities in life and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>In other words , the image in the TV comercial...</td>\n",
       "      <td>['In other words , the image in the TV commerc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>Members gather money for the funeral and help ...</td>\n",
       "      <td>['Members gather money for the funeral to help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>NaN</td>\n",
       "      <td>['' '' '' '']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1503 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  \\\n",
       "0     So I think we can not live if old people could...   \n",
       "1                                    For not use car .    \n",
       "2     Here was no promise of morning except that we ...   \n",
       "3     Thus even today sex is considered as the least...   \n",
       "4     image you salf you are wark in factory just to...   \n",
       "...                                                 ...   \n",
       "1498  But I disegree this opinion because often the ...   \n",
       "1499  it gives him many apprtunites in the life , an...   \n",
       "1500  In other words , the image in the TV comercial...   \n",
       "1501  Members gather money for the funeral and help ...   \n",
       "1502                                                NaN   \n",
       "\n",
       "                                            corrections  \n",
       "0     ['So I think we would not be alive if our ance...  \n",
       "1     ['Not for use with a car . ' 'Do not use in th...  \n",
       "2     ['Here was no promise of morning , except that...  \n",
       "3     ['Thus , even today , sex is considered as the...  \n",
       "4     [\"Imagine yourself you are working in factory ...  \n",
       "...                                                 ...  \n",
       "1498  [\"But I disagree with this opinion because oft...  \n",
       "1499  ['It gives him many opportunities in life and ...  \n",
       "1500  ['In other words , the image in the TV commerc...  \n",
       "1501  ['Members gather money for the funeral to help...  \n",
       "1502                                      ['' '' '' '']  \n",
       "\n",
       "[1503 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge dataset using concat\n",
    "df = pd.concat([pd.read_csv(f) for f in csv_files ], ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e6f4be8e-c7a9-4069-adf0-ec07fcc38836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your PDF file\n",
    "pdf_path = 'Resume - Rich Andiety.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2bc133fa-1c5b-4be4-95da-f7ebc1a6120c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>corrections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;start&gt; So I think we can not live if old peop...</td>\n",
       "      <td>['So I think we would not be alive if our ance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;start&gt; For not use car .</td>\n",
       "      <td>['Not for use with a car . ' 'Do not use in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;start&gt; Here was no promise of morning except ...</td>\n",
       "      <td>['Here was no promise of morning , except that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;start&gt; Thus even today sex is considered as t...</td>\n",
       "      <td>['Thus , even today , sex is considered as the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;start&gt; image you salf you are wark in factory...</td>\n",
       "      <td>[\"Imagine yourself you are working in factory ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>&lt;start&gt; But I disegree this opinion because of...</td>\n",
       "      <td>[\"But I disagree with this opinion because oft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>&lt;start&gt; it gives him many apprtunites in the l...</td>\n",
       "      <td>['It gives him many opportunities in life and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>&lt;start&gt; In other words , the image in the TV c...</td>\n",
       "      <td>['In other words , the image in the TV commerc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>&lt;start&gt; Members gather money for the funeral a...</td>\n",
       "      <td>['Members gather money for the funeral to help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>NaN</td>\n",
       "      <td>['' '' '' ''] &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1503 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  \\\n",
       "0     <start> So I think we can not live if old peop...   \n",
       "1                            <start> For not use car .    \n",
       "2     <start> Here was no promise of morning except ...   \n",
       "3     <start> Thus even today sex is considered as t...   \n",
       "4     <start> image you salf you are wark in factory...   \n",
       "...                                                 ...   \n",
       "1498  <start> But I disegree this opinion because of...   \n",
       "1499  <start> it gives him many apprtunites in the l...   \n",
       "1500  <start> In other words , the image in the TV c...   \n",
       "1501  <start> Members gather money for the funeral a...   \n",
       "1502                                                NaN   \n",
       "\n",
       "                                            corrections  \n",
       "0     ['So I think we would not be alive if our ance...  \n",
       "1     ['Not for use with a car . ' 'Do not use in th...  \n",
       "2     ['Here was no promise of morning , except that...  \n",
       "3     ['Thus , even today , sex is considered as the...  \n",
       "4     [\"Imagine yourself you are working in factory ...  \n",
       "...                                                 ...  \n",
       "1498  [\"But I disagree with this opinion because oft...  \n",
       "1499  ['It gives him many opportunities in life and ...  \n",
       "1500  ['In other words , the image in the TV commerc...  \n",
       "1501  ['Members gather money for the funeral to help...  \n",
       "1502                                ['' '' '' ''] <end>  \n",
       "\n",
       "[1503 rows x 2 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define start and end tokens\n",
    "df['sentence']= '<start> ' + df['sentence']\n",
    "df['corrections'] =  df['corrections'] + ' <end>' \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7fe750e2-bca2-4a27-90bb-91eeba1aaeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add start and end tokens to target_texts\n",
    "input_texts = df['sentence'].astype(str).tolist()\n",
    "target_texts = [start_token + \" \" + text + \" \" + end_token for text in df['corrections'].astype(str).tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "911075fd-fa96-40ec-a1e7-10b94ae1bfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(input_texts + target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bee8bd8e-92bb-4a22-ba17-25656ab24839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tokenizer for later use in text generation\n",
    "import pickle\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e24906d5-a630-4524-9ae5-f1c4f2aacf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert texts to sequences\n",
    "input_sequences = tokenizer.texts_to_sequences(input_texts)\n",
    "target_sequences = tokenizer.texts_to_sequences(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "14842cc3-4c15-4dfd-a806-ae9c9608593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding sequences\n",
    "max_seq_length = max(max(len(seq) for seq in input_sequences), max(len(seq) for seq in target_sequences))\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_seq_length, padding='post')\n",
    "target_sequences = pad_sequences(target_sequences, maxlen=max_seq_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1eff4bc2-830c-4c02-a3e5-0dd1ea1d8234",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1  # Plus 1 for padding\n",
    "embedding_dim = 128\n",
    "lstm_units = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "383ab1f6-d5b3-4857-aae6-bc9587c958a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "encoder_embedding = Embedding(vocab_size, embedding_dim)(encoder_inputs)\n",
    "encoder_lstm = LSTM(lstm_units, return_state=True)\n",
    "_, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "138b6bb9-20d8-4479-8317-a924ec457bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "decoder_embedding = Embedding(vocab_size, embedding_dim)(decoder_inputs)\n",
    "decoder_lstm = LSTM(lstm_units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f2d00360-9312-43d6-956d-8a81e480e4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 65s 3s/step - loss: 5.0778\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 66s 3s/step - loss: 2.0128\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 65s 3s/step - loss: 1.8512\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 58s 2s/step - loss: 1.8298\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 65s 3s/step - loss: 2.2293\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 62s 3s/step - loss: 2.0125\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 66s 3s/step - loss: 1.7111\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 58s 2s/step - loss: 1.6175\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 57s 2s/step - loss: 1.5739\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 59s 2s/step - loss: 1.5566\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2941f95b0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Reshape target data to be 3D\n",
    "target_sequences = target_sequences.reshape((target_sequences.shape[0], target_sequences.shape[1], 1))\n",
    "\n",
    "# Train model\n",
    "model.fit([input_sequences, target_sequences[:, :-1]], target_sequences[:, 1:], batch_size=64, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7f1ce668-147f-4fc3-88b0-26fd8aa40364",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/angelatiaramaharanisitorus/micromamba/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('grammar_correction_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f2de58de-d2f0-47da-8a43-b01124850f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token '<start>' added to tokenizer.\n"
     ]
    }
   ],
   "source": [
    "def update_tokenizer(tokenizer_file_path, new_token='<start>'):\n",
    "    # Load the tokenizer\n",
    "    with open('tokenizer.pickle', 'rb') as handle:\n",
    "        tokenizer = pickle.load(handle)\n",
    "\n",
    "    # Check if the new token is in the tokenizer's word index\n",
    "    if new_token not in tokenizer.word_index:\n",
    "        # Add the new token to the tokenizer's word index\n",
    "        new_index = len(tokenizer.word_index) + 1\n",
    "        tokenizer.word_index[new_token] = new_index\n",
    "        tokenizer.index_word[new_index] = new_token\n",
    "\n",
    "        # Save the updated tokenizer\n",
    "        with open(tokenizer_file_path, 'wb') as handle:\n",
    "            pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        print(f\"Token '{new_token}' added to tokenizer.\")\n",
    "    else:\n",
    "        print(f\"Token '{new_token}' already exists in the tokenizer.\")\n",
    "\n",
    "# Update the tokenizer with the '<start>' token\n",
    "tokenizer_file_path = 'tokenizer.pickle'  # Update with the correct path\n",
    "update_tokenizer(tokenizer_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "25cbd073-5027-4c06-a428-bf69ac4de33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_correction(input_seq):\n",
    "    # Preprocess the input sequence\n",
    "    tokenized_input = tokenizer.texts_to_sequences([input_seq])\n",
    "    padded_input = pad_sequences(tokenized_input, maxlen=max_seq_length, padding='post')\n",
    "\n",
    "    # Assuming the first part of the model is the encoder\n",
    "    # and the second part is the decoder\n",
    "    encoder_model = Model(model.input[0], model.layers[2].output)\n",
    "    decoder_model = Model(model.input[1], model.layers[4].output)\n",
    "\n",
    "    # Get the encoder's state\n",
    "    encoder_states = encoder_model.predict(padded_input)\n",
    "\n",
    "    # Initialize the decoder's input as a sequence with only the start token\n",
    "    start_token_idx = tokenizer.word_index['<start>']\n",
    "    decoder_input = np.array([[start_token_idx]])\n",
    "\n",
    "    # Generate the sequence\n",
    "    corrected_sentence = []\n",
    "    for i in range(max_seq_length):\n",
    "        # Predict the next token using the decoder\n",
    "        decoder_output, state_h, state_c = decoder_model.predict([decoder_input] + encoder_states)\n",
    "        next_token = np.argmax(decoder_output[0, -1, :])\n",
    "\n",
    "        # Add the predicted token to the sequence\n",
    "        if next_token == tokenizer.word_index['<end>']:\n",
    "            break\n",
    "\n",
    "        corrected_sentence.append(next_token)\n",
    "        decoder_input = np.array([[next_token]])\n",
    "\n",
    "        # Update the states\n",
    "        encoder_states = [state_h, state_c]\n",
    "\n",
    "    # Convert indices to words\n",
    "    corrected_sentence = tokenizer.sequences_to_texts([corrected_sentence])[0]\n",
    "    return corrected_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "893e7a3d-bcf7-470f-9663-bd3371ef5fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = ''\n",
    "        for page_num in range(len(reader.pages)):  # Corrected variable name here\n",
    "            text += reader.pages[page_num].extract_text()  # Use 'page_num' instead of 'page_number'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7335ce96-face-452c-a3c4-5ee6f47d1746",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Split the text into sentences\n",
    "sentences = sent_tokenize(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3107f6d6-45d3-47c5-bc50-cd7a3be4d2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_grammar(text):\n",
    "    tool = language_tool_python.LanguageTool('en-US')\n",
    "    matches = tool.check(text)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "488bbaa3-9a40-47cd-b97b-daf04a57a103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_sentences_with_suggestions(text, matches):\n",
    "    sentences = sent_tokenize(text)\n",
    "    error_sentences = set()\n",
    "    suggestions = {}\n",
    "\n",
    "    for match in matches:\n",
    "        for i, sentence in enumerate(sentences):\n",
    "            if match.offset >= text.find(sentence) and match.offset < text.find(sentence) + len(sentence):\n",
    "                error_sentences.add(i)\n",
    "                suggestions[i] = suggestions.get(i, []) + [(match.context, match.replacements[0] if match.replacements else \"No suggestion\")]\n",
    "\n",
    "    highlighted_text = \"\"\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        if i in error_sentences:\n",
    "            highlighted_text += f'**{sentence}**\\n'\n",
    "            for context, suggestion in suggestions[i]:\n",
    "                highlighted_text += f'Error: \"{context}\" -> Suggestion: {suggestion}\\n'\n",
    "        else:\n",
    "            highlighted_text += sentence + '\\n'\n",
    "\n",
    "    return highlighted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e143b3b1-f5af-45b3-8cf4-4470baf44923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**RICH ANDIETY  \n",
      "082135324409  | andietyrich @gmail.com  | https://www.linkedin.com/in/andietyrich/  \n",
      "Gajahmungkur, Semarang  \n",
      "As a final year student majoring in Informatics, I am a highly driven and ambitious individual with a  strong passion \n",
      "for technology.**\n",
      "Error: \"RICH ANDIETY   082135324409  | andietyrich @gmail.co...\" -> Suggestion: ANXIETY\n",
      "Error: \"RICH ANDIETY   082135324409  | andietyrich @gmail.com ...\" -> Suggestion:  \n",
      "Error: \"RICH ANDIETY   082135324409  | andietyrich @gmail.com  | https://www....\" -> Suggestion:  \n",
      "Error: \"RICH ANDIETY   082135324409  | andietyrich @gmail.com  | https://www.linkedin.com/...\" -> Suggestion: Dietrich\n",
      "Error: \"...  082135324409  | andietyrich @gmail.com  | https://www.linkedin.com/in/andietyric...\" -> Suggestion:  \n",
      "Error: \"...https://www.linkedin.com/in/andietyrich/   Gajahmungkur, Semarang   As a final yea...\" -> Suggestion:  \n",
      "Error: \"...ps://www.linkedin.com/in/andietyrich/   Gajahmungkur, Semarang   As a final year student maj...\" -> Suggestion: No suggestion\n",
      "Error: \"...in/andietyrich/   Gajahmungkur, Semarang   As a final year student majoring in Inf...\" -> Suggestion:  \n",
      "Error: \"...y driven and ambitious individual with a  strong passion  for technology. Recogniz...\" -> Suggestion:  \n",
      "Recognized as a highly disciplined person with exceptional communication and adaptation skills, \n",
      "I possess a unique blend of expertise in front -end developing, data science and marketing.\n",
      "**Combining my analytical nature, publ ic speaking capability, marketing expertise, and IT knowledge, I am prepared \n",
      "to make a significant impact in any organization.**\n",
      "Error: \"...ting.   Combining my analytical nature, publ ic speaking capability, marketing expertis...\" -> Suggestion: public\n",
      "**If you are seeking a results -oriented professional with a passion \n",
      "for driving innovation and achieving excellence, let's connect and explore how I can contribute to your success.**\n",
      "Error: \"...in any organization. If you are seeking a results -oriented professional with a passion  ...\" -> Suggestion: a result\n",
      "**Work Experiences    \n",
      "PT.**\n",
      "Error: \"...bute to your success.   Work Experiences     PT. Telkom Akses  - Semarang    Program...\" -> Suggestion:  \n",
      "**Telkom Akses  - Semarang   \n",
      "Programmer Intern   \n",
      "â€¢ Creating and maintaining employee attendance Telegram Chatbot  \n",
      "â€¢ Creating and maintaining E -Certificate Telegram Chatbot  \n",
      "  \n",
      "Informatics Lab Telkom University  - Bandung  Feb 2023 â€“ Jun 2023  \n",
      "Computer Network Practicum Assistant   \n",
      "â€¢ Guiding practicum for students who take Computer Network class  \n",
      "â€¢ Guiding 2 regular clas s and 1 International Class for Informatics Majo r \n",
      "â€¢ Held in the even semester of the 2022/2023 academic year   \n",
      " \n",
      "Education Level    \n",
      "TELKOM UNIVERSITY  - Bandung   \n",
      " \n",
      "Sep 2020 -  Present   \n",
      "Undergraduate in Informatics , 3.47/4.00  \n",
      "â€¢ Successfully completed a software development innovation project with a team  \n",
      "â€¢ Actively participates in student organizations  \n",
      "â€¢ Completed Level 2 leadership training for student organization  \n",
      " \n",
      "SMA  PL DON BOSKO  â€“ Semarang          Jul 2017 â€“ Jun 2020  \n",
      "Highschool Di ploma, Science  \n",
      "â€¢ Actively participates in extracullicu lar activities  \n",
      "â€¢ Silver Medalist at Yogyakarta Open Championship 2017  \n",
      "â€¢ Bronze Medalist at Perisai Diri Cup Semarang 2018  \n",
      "â€¢ Bronze Medalist at Semarang Open Championship 2018  \n",
      "Organisational and V olunteer Experience    \n",
      "BPM  IF - Bandung    \n",
      "Apr 2022 - Present   \n",
      "Aspiration Commission Staff  \n",
      "Student Representative Council of Informatics  Major \n",
      "â€¢ Accommodat e, receiv e, and proce ssing aspirations from Telkom University Undergraduate Informatics student s \n",
      " \n",
      "Fortran  - Bandung  Jun 2022 - Nov 2022   \n",
      "Disciplinary Commission Staff   \n",
      "Informati cs major l eadership training   \n",
      "Create rules for participants and the organi zing committee s   \n",
      "Provide sanctions to students and committees who violate the rules  \n",
      "Responsible for licensing participants and committee members    \n",
      "Panda FIF  - Bandung  Jul 2021 - Jan 2022   \n",
      "Creative Divis ion Staff   \n",
      "Telkom University Faculty of Informatics Graduation Award   \n",
      "Designing decorations for graduation awards activities    \n",
      "Making venue and stage decorations for graduation awards activities    \n",
      "Skills, Achievements & Other Experience    \n",
      "Soft Skills : Leadership, Public Speaking, Communication, Adaptation, Problem Solving    \n",
      "Hard Skills : Python, Go, Java, C++    \n",
      "Achievements : English Proficiency Test (EPrT) = 5 67/633 (2020), English Communicative Test  (ECCT) = 3.00/4.00 (2021)**\n",
      "Error: \"...our success.   Work Experiences     PT. Telkom Akses  - Semarang    Programmer Intern ...\" -> Suggestion: Seldom\n",
      "Error: \"...cess.   Work Experiences     PT. Telkom Akses  - Semarang    Programmer Intern    â€¢ C...\" -> Suggestion: Apses\n",
      "Error: \"...   Work Experiences     PT. Telkom Akses  - Semarang    Programmer Intern    â€¢ Cre...\" -> Suggestion:  \n",
      "Error: \"...riences     PT. Telkom Akses  - Semarang    Programmer Intern    â€¢ Creating and mai...\" -> Suggestion:  \n",
      "Error: \"...m Akses  - Semarang    Programmer Intern    â€¢ Creating and maintaining employee att...\" -> Suggestion:  \n",
      "Error: \"...ing employee attendance Telegram Chatbot   â€¢ Creating and maintaining E -Certifica...\" -> Suggestion:  \n",
      "Error: \"...ntaining E -Certificate Telegram Chatbot      Informatics Lab Telkom University  -...\" -> Suggestion:  \n",
      "Error: \"...e Telegram Chatbot      Informatics Lab Telkom University  - Bandung  Feb 2023 â€“ Jun 2...\" -> Suggestion: Seldom\n",
      "Error: \"...t      Informatics Lab Telkom University  - Bandung  Feb 2023 â€“ Jun 2023   Compute...\" -> Suggestion:  \n",
      "Error: \"...rmatics Lab Telkom University  - Bandung  Feb 2023 â€“ Jun 2023   Computer Network P...\" -> Suggestion:  \n",
      "Error: \"...iversity  - Bandung  Feb 2023 â€“ Jun 2023   Computer Network Practicum Assistant   ...\" -> Suggestion:  \n",
      "Error: \"...3   Computer Network Practicum Assistant    â€¢ Guiding practicum for students who ta...\" -> Suggestion:  \n",
      "Error: \"...students who take Computer Network class   â€¢ Guiding 2 regular clas s and 1 Intern...\" -> Suggestion:  \n",
      "Error: \"...ter Network class   â€¢ Guiding 2 regular clas s and 1 International Class for Informati...\" -> Suggestion: class\n",
      "Error: \"...d 1 International Class for Informatics Majo r  â€¢ Held in the even semester of the 202...\" -> Suggestion: Major\n",
      "Error: \"... semester of the 2022/2023 academic year      Education Level     TELKOM UNIVERSITY...\" -> Suggestion:  \n",
      "Error: \".../2023 academic year      Education Level     TELKOM UNIVERSITY  - Bandung      Sep 2...\" -> Suggestion:  \n",
      "Error: \"... academic year      Education Level     TELKOM UNIVERSITY  - Bandung      Sep 2020 -  ...\" -> Suggestion: SELDOM\n",
      "Error: \"...   Education Level     TELKOM UNIVERSITY  - Bandung      Sep 2020 -  Present    Un...\" -> Suggestion:  \n",
      "Error: \"...n Level     TELKOM UNIVERSITY  - Bandung      Sep 2020 -  Present    Undergraduate ...\" -> Suggestion:  \n",
      "Error: \"...OM UNIVERSITY  - Bandung      Sep 2020 -  Present    Undergraduate in Informatics ...\" -> Suggestion:  \n",
      "Error: \"...SITY  - Bandung      Sep 2020 -  Present    Undergraduate in Informatics , 3.47/4.0...\" -> Suggestion:  \n",
      "Error: \"... Present    Undergraduate in Informatics , 3.47/4.00   â€¢ Successfully completed a ...\" -> Suggestion: ,\n",
      "Error: \"...Undergraduate in Informatics , 3.47/4.00   â€¢ Successfully completed a software dev...\" -> Suggestion:  \n",
      "Error: \"...velopment innovation project with a team   â€¢ Actively participates in student orga...\" -> Suggestion:  \n",
      "Error: \"...ly participates in student organizations   â€¢ Completed Level 2 leadership training...\" -> Suggestion:  \n",
      "Error: \"...ership training for student organization     SMA  PL DON BOSKO  â€“ Semarang        ...\" -> Suggestion:  \n",
      "Error: \"...raining for student organization     SMA  PL DON BOSKO  â€“ Semarang          Jul 20...\" -> Suggestion:  \n",
      "Error: \"...or student organization     SMA  PL DON BOSKO  â€“ Semarang          Jul 2017 â€“ Jun 202...\" -> Suggestion: BOS KO\n",
      "Error: \"...udent organization     SMA  PL DON BOSKO  â€“ Semarang          Jul 2017 â€“ Jun 2020 ...\" -> Suggestion:  \n",
      "Error: \"...zation     SMA  PL DON BOSKO  â€“ Semarang          Jul 2017 â€“ Jun 2020   Highschool Di plom...\" -> Suggestion:  \n",
      "Error: \"... â€“ Semarang          Jul 2017 â€“ Jun 2020   Highschool Di ploma, Science   â€¢ Active...\" -> Suggestion:  \n",
      "Error: \"...Semarang          Jul 2017 â€“ Jun 2020   Highschool Di ploma, Science   â€¢ Actively particip...\" -> Suggestion: High school\n",
      "Error: \"...       Jul 2017 â€“ Jun 2020   Highschool Di ploma, Science   â€¢ Actively participates in e...\" -> Suggestion: Diploma\n",
      "Error: \"... Jun 2020   Highschool Di ploma, Science   â€¢ Actively participates in extracullicu...\" -> Suggestion:  \n",
      "Error: \"...a, Science   â€¢ Actively participates in extracullicu lar activities   â€¢ Silver Medalist at Y...\" -> Suggestion: No suggestion\n",
      "Error: \"...â€¢ Actively participates in extracullicu lar activities   â€¢ Silver Medalist at Yogya...\" -> Suggestion: LAR\n",
      "Error: \"...ticipates in extracullicu lar activities   â€¢ Silver Medalist at Yogyakarta Open Ch...\" -> Suggestion:  \n",
      "Error: \"...u lar activities   â€¢ Silver Medalist at Yogyakarta Open Championship 2017   â€¢ Bronze Medal...\" -> Suggestion: Jogjakarta\n",
      "Error: \"...ist at Yogyakarta Open Championship 2017   â€¢ Bronze Medalist at Perisai Diri Cup S...\" -> Suggestion:  \n",
      "Error: \"...hampionship 2017   â€¢ Bronze Medalist at Perisai Diri Cup Semarang 2018   â€¢ Bronze Medal...\" -> Suggestion: Persian\n",
      "Error: \"...hip 2017   â€¢ Bronze Medalist at Perisai Diri Cup Semarang 2018   â€¢ Bronze Medalist a...\" -> Suggestion: Dirt\n",
      "Error: \"...dalist at Perisai Diri Cup Semarang 2018   â€¢ Bronze Medalist at Semarang Open Cham...\" -> Suggestion:  \n",
      "Error: \"...alist at Semarang Open Championship 2018   Organisational and V olunteer Experienc...\" -> Suggestion:  \n",
      "Error: \"...st at Semarang Open Championship 2018   Organisational and V olunteer Experience     BPM  IF -...\" -> Suggestion: Organizational\n",
      "Error: \"... Championship 2018   Organisational and V olunteer Experience     BPM  IF - Bandung     Ap...\" -> Suggestion: Volunteer\n",
      "Error: \"...Organisational and V olunteer Experience     BPM  IF - Bandung     Apr 2022 - Presen...\" -> Suggestion:  \n",
      "Error: \"...tional and V olunteer Experience     BPM  IF - Bandung     Apr 2022 - Present    A...\" -> Suggestion:  \n",
      "Error: \"...lunteer Experience     BPM  IF - Bandung     Apr 2022 - Present    Aspiration Commis...\" -> Suggestion:  \n",
      "Error: \"...BPM  IF - Bandung     Apr 2022 - Present    Aspiration Commission Staff   Student R...\" -> Suggestion:  \n",
      "Error: \"...- Present    Aspiration Commission Staff   Student Representative Council of Infor...\" -> Suggestion:  \n",
      "Error: \"...nt Representative Council of Informatics  Major  â€¢ Accommodat e, receiv e, and pro...\" -> Suggestion:  \n",
      "Error: \"...tative Council of Informatics  Major  â€¢ Accommodat e, receiv e, and proce ssing aspirations ...\" -> Suggestion: Accommodate\n",
      "Error: \"... of Informatics  Major  â€¢ Accommodat e, receiv e, and proce ssing aspirations from Telko...\" -> Suggestion: receive\n",
      "Error: \"...s  Major  â€¢ Accommodat e, receiv e, and proce ssing aspirations from Telkom University Unde...\" -> Suggestion: processing\n",
      "Error: \"...eiv e, and proce ssing aspirations from Telkom University Undergraduate Informatics st...\" -> Suggestion: Seldom\n",
      "Error: \"... Undergraduate Informatics student s    Fortran  - Bandung  Jun 2022 - Nov 2022    Disc...\" -> Suggestion: FORTRAN\n",
      "Error: \"...raduate Informatics student s    Fortran  - Bandung  Jun 2022 - Nov 2022    Discip...\" -> Suggestion:  \n",
      "Error: \"...ormatics student s    Fortran  - Bandung  Jun 2022 - Nov 2022    Disciplinary Comm...\" -> Suggestion:  \n",
      "Error: \"... Fortran  - Bandung  Jun 2022 - Nov 2022    Disciplinary Commission Staff    Inform...\" -> Suggestion:  \n",
      "Error: \"...ov 2022    Disciplinary Commission Staff    Informati cs major l eadership training...\" -> Suggestion:  \n",
      "Error: \"...022    Disciplinary Commission Staff    Informati cs major l eadership training    Create ru...\" -> Suggestion: Informatics\n",
      "Error: \"... Commission Staff    Informati cs major l eadership training    Create rules for participan...\" -> Suggestion: leadership\n",
      "Error: \"... Informati cs major l eadership training    Create rules for participants and the o...\" -> Suggestion:  \n",
      "Error: \"...  Create rules for participants and the organi zing committee s    Provide sanctions to stu...\" -> Suggestion: organizing\n",
      "Error: \"...icipants and the organi zing committee s    Provide sanctions to students and commi...\" -> Suggestion:  \n",
      "Error: \"...nts and committees who violate the rules   Responsible for licensing participants ...\" -> Suggestion:  \n",
      "Error: \"...nsing participants and committee members     Panda FIF  - Bandung  Jul 2021 - Jan 20...\" -> Suggestion:  \n",
      "Error: \"...ants and committee members     Panda FIF  - Bandung  Jul 2021 - Jan 2022    Creati...\" -> Suggestion:  \n",
      "Error: \"...mmittee members     Panda FIF  - Bandung  Jul 2021 - Jan 2022    Creative Divis io...\" -> Suggestion:  \n",
      "Error: \"...anda FIF  - Bandung  Jul 2021 - Jan 2022    Creative Divis ion Staff    Telkom Univ...\" -> Suggestion:  \n",
      "Error: \"...andung  Jul 2021 - Jan 2022    Creative Divis ion Staff    Telkom University Faculty of I...\" -> Suggestion: Division\n",
      "Error: \"...1 - Jan 2022    Creative Divis ion Staff    Telkom University Faculty of Informatic...\" -> Suggestion:  \n",
      "Error: \"...Jan 2022    Creative Divis ion Staff    Telkom University Faculty of Informatics Gradu...\" -> Suggestion: Seldom\n",
      "Error: \"... Faculty of Informatics Graduation Award    Designing decorations for graduation aw...\" -> Suggestion:  \n",
      "Error: \"...rations for graduation awards activities     Making venue and stage decorations for ...\" -> Suggestion:  \n",
      "Error: \"...rations for graduation awards activities     Skills, Achievements & Other Experience...\" -> Suggestion:  \n",
      "Error: \"... Skills, Achievements & Other Experience     Soft Skills : Leadership, Public Speaki...\" -> Suggestion:  \n",
      "Error: \"...ic Speaking, Communication, Adaptation, Problem Solving     Hard Skills : Python, Go, Java, C++...\" -> Suggestion: Problem-Solving\n",
      "Error: \"...mmunication, Adaptation, Problem Solving     Hard Skills : Python, Go, Java, C++    ...\" -> Suggestion:  \n",
      "Error: \"...     Hard Skills : Python, Go, Java, C++     Achievements : English Proficiency Test...\" -> Suggestion:  \n",
      "Error: \"...chievements : English Proficiency Test (EPrT) = 5 67/633 (2020), English Communicati...\" -> Suggestion: EPR\n",
      "Error: \"...7/633 (2020), English Communicative Test  (ECCT) = 3.00/4.00 (2021)        \" -> Suggestion:  \n",
      "Error: \"...33 (2020), English Communicative Test  (ECCT) = 3.00/4.00 (2021)        \" -> Suggestion: ECCL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extracted_text = extract_text_from_pdf(pdf_path)\n",
    "grammar_matches = check_grammar(extracted_text)\n",
    "highlighted_text_with_suggestions = highlight_sentences_with_suggestions(extracted_text, grammar_matches)\n",
    "print(highlighted_text_with_suggestions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
